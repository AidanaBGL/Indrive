# pip install -U "transformers>=4.44" "accelerate>=0.34" pillow torchvision timm sentencepiece safetensors streamlit python-dotenv deepface
import base64
import io
import json
from dataclasses import dataclass
from typing import Optional, Tuple

import numpy as np
from PIL import Image
from deepface import DeepFace
import streamlit as st

# ==== Qwen2.5-VL ====
import torch
from transformers import AutoProcessor, Qwen2_5_VLForConditionalGeneration

# --- (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π) —Ñ–æ–ª–±—ç–∫, –µ—Å–ª–∏ –Ω–µ—Ç qwen_vl_utils.process_vision_info ---
try:
    from qwen_vl_utils import process_vision_info
except Exception:
    def process_vision_info(messages):
        """–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ñ–æ–ª–±—ç–∫: –≤—ã—Ç–∞—â–∏—Ç—å PIL-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ messages.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (image_inputs, video_inputs) –∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä Qwen.
        """
        image_inputs = []
        for msg in messages:
            for item in msg.get("content", []):
                if item.get("type") == "image":
                    image_inputs.append(item["image"])  # PIL.Image –∏–ª–∏ –ø—É—Ç—å
        return image_inputs, None

# ---------- –£—Ç–∏–ª–∏—Ç—ã ----------
def file_to_pil(uploaded) -> Image.Image:
    return Image.open(io.BytesIO(uploaded.getvalue())).convert("RGB")

def pil_to_cv(img: Image.Image):
    # DeepFace –ø—Ä–∏–Ω–∏–º–∞–µ—Ç numpy ∆í√ßBGR –∏–ª–∏ –ø—É—Ç—å; –∏—Å–ø–æ–ª—å–∑—É–µ–º RGB->BGR
    arr = np.array(img)[:, :, ::-1]
    return arr

def pil_to_data_url(img: Image.Image, format="JPEG") -> str:
    buf = io.BytesIO()
    img.save(buf, format=format, quality=92)
    b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
    return f"data:image/{format.lower()};base64,{b64}"
√ß
# ---------- Qwen2.5-VL –∑–∞–≥—Ä—É–∑–∫–∞ (–∫—ç—à–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å –∫–∞–∂–¥—ã–π —Ä–∞–∑) ----------
@st.cache_resource(show_spinner=True)
def load_qwen():
    device = "cuda" if torch.cuda.is_available() else ("mps" if getattr(torch.backends, "mps", None) and torch.backends.mps.is_available() else "cpu")
    dtype = torch.float16 if device == "cuda" else torch.float32

    model_id = "Qwen/Qwen2.5-VL-7B-Instruct"
    processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)
    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        model_id,
        torch_dtype="auto",
        device_map="auto",
        trust_remote_code=True,
    )
    return processor, model

# ---------- –°–≤–µ—Ä–∫–∞ –¥–≤—É—Ö –ª–∏—Ü –≤ –æ–¥–Ω–æ–º —Ñ–æ—Ç–æ —á–µ—Ä–µ–∑ DeepFace ----------
def verify_two_faces_in_one(image: Image.Image) -> Tuple[bool, Optional[float], Optional[str], int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (matched, distance, error_message, num_faces)
    matched=True —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤ –∫–∞–¥—Ä–µ —Ä–æ–≤–Ω–æ 2 –ª–∏—Ü–∞ (—á–µ–ª–æ–≤–µ–∫ + —Ñ–æ—Ç–æ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–µ) –∏ –æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç.
    """
    try:
        arr_bgr = pil_to_cv(image)
        faces = DeepFace.extract_faces(
            img_path=arr_bgr,
            detector_backend="retinaface",
            enforce_detection=False
        )
        num_faces = len(faces)

        if num_faces < 2:
            return False, None, (
                "–ù–∞ —Å–Ω–∏–º–∫–µ –Ω–∞–π–¥–µ–Ω–æ –º–µ–Ω—å—à–µ –¥–≤—É—Ö –ª–∏—Ü. –î–µ—Ä–∂–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç –±–ª–∏–∂–µ –∫ –∫–∞–º–µ—Ä–µ –∏ —Å–ª–µ–¥–∏—Ç–µ, "
                "—á—Ç–æ–±—ã –ø–æ—Ä—Ç—Ä–µ—Ç –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–µ –±—ã–ª —Ö–æ—Ä–æ—à–æ –≤–∏–¥–µ–Ω."
            ), num_faces

        if num_faces > 2:
            return False, None, (
                "–ù–∞ —Å–Ω–∏–º–∫–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –±–æ–ª—å—à–µ –¥–≤—É—Ö –ª–∏—Ü. –£–±–µ—Ä–∏—Ç–µ –ª–∏—à–Ω–∏—Ö –ª—é–¥–µ–π –∏–∑ –∫–∞–¥—Ä–∞."
            ), num_faces

        # –†–æ–≤–Ω–æ 2 –ª–∏—Ü–∞ ‚Üí —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º
        f1 = faces[0]["face"]
        f2 = faces[1]["face"]
        result = DeepFace.verify(
            img1_path=f1,
            img2_path=f2,
            model_name="Facenet512",
            detector_backend="opencv",   # –¥–µ—Ç–µ–∫—Ç–æ—Ä –Ω–µ –Ω—É–∂–µ–Ω (—É –Ω–∞—Å —É–∂–µ –∫—Ä–æ–ø—ã), –Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
            enforce_detection=False
        )
        matched = bool(result.get("verified", False))
        distance = float(result.get("distance", 0.0))
        return matched, distance, None, num_faces

    except Exception as e:
        return False, None, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ª–∏—Ü: {e}", 0

# ---------- –í–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∞–≤—Ç–æ —á–µ—Ä–µ–∑ Qwen2.5-VL ----------
SYSTEM_PROMPT = (
    "–¢—ã ‚Äî –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä –∞–≤—Ç–æ. –¢–≤–æ—è –∑–∞–¥–∞—á–∞: –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∫—É—Ä—Å (front|side-left|side-right|rear), "
    "—á–∏—Å—Ç–æ—Ç—É (clean: true/false), –µ—Å—Ç—å –ª–∏ –≤–∏–¥–∏–º—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è (damage: true/false), –∏ –∫—Ä–∞—Ç–∫–∏–µ –∑–∞–º–µ—Ç–∫–∏. "
    "–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON –ø–æ —Å—Ö–µ–º–µ: "
    '{"angle":"front|side-left|side-right|rear","clean":true/false,"damage":true/false,"notes":"—Å—Ç—Ä–æ–∫–∞"}'
)

def analyze_car_image(img: Image.Image) -> dict:
    """–¢–æ—Ç –∂–µ —Å—Ü–µ–Ω–∞—Ä–∏–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞, –Ω–æ —á–µ—Ä–µ–∑ Qwen2.5-VL; –±–µ–∑ –≤—ã–¥—É–º–æ–∫, —Ç–æ–ª—å–∫–æ —Ñ–æ—Ç–æ."""
    processor, model = load_qwen()

    user_prompt = (
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–æ—Ç–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è. –û–ø—Ä–µ–¥–µ–ª–∏ —Ä–∞–∫—É—Ä—Å (front/side-left/side-right/rear), "
        "—á–∏—Å—Ç–æ—Ç—É (clean) –∏ –Ω–∞–ª–∏—á–∏–µ –≤–∏–¥–∏–º—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π (damage). –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON."
    )

    # —Å—Ç—Ä–æ–∏–º messages —Å—Ç—Ä–æ–≥–æ –ø–æ–¥ Qwen –∫–∞–∫ –≤ –∏—Ö –ø—Ä–∏–º–µ—Ä–µ
    messages = [
        {"role": "system", "content": [{"type": "text", "text": SYSTEM_PROMPT}]},
        {"role": "user", "content": [{"type": "text", "text": user_prompt},
                                     {"type": "image", "image": img}]},
    ]

    # 1) —Å—Ç—Ä–æ–∫–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
    text = processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)

    # 2) –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –≤—Ö–æ–¥—ã
    image_inputs, video_inputs = process_vision_info(messages)

    # 3) –ø–∞–∫—É–µ–º
    inputs = processor(
        text=[text],
        images=image_inputs,
        videos=video_inputs,
        return_tensors="pt",
    )

    # 4) –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    # 5) –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
    with torch.no_grad():
        generated_ids = model.generate(
            **inputs,
            max_new_tokens=200,
            temperature=0.3,   # –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Å—Ç–∏—á–Ω–µ–µ –¥–ª—è –ø—Ä–æ–¥-–ª–æ–≥–∏–∫–∏
        )

    # –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã
    new_tokens = generated_ids[:, inputs["input_ids"].shape[1]:]
    text_out = processor.batch_decode(
        new_tokens, skip_special_tokens=True, clean_up_tokenization_spaces=False
    )[0].strip()

    # –ø–æ–ø—ã—Ç–∫–∞ –≤—ã–¥—Ä–∞—Ç—å JSON
    try:
        first_brace = text_out.find("{")
        last_brace = text_out.rfind("}")
        if first_brace != -1 and last_brace != -1:
            text_out = text_out[first_brace:last_brace+1]
        parsed = json.loads(text_out)
        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–∏–ø—ã/–∫–ª—é—á–∏
        return {
            "angle": str(parsed.get("angle", "unknown")),
            "clean": bool(parsed.get("clean", False)),
            "damage": bool(parsed.get("damage", True)),
            "notes": str(parsed.get("notes", "")),
        }
    except Exception:
        return {"angle": "unknown", "clean": False, "damage": True, "notes": "parse_error"}

# ---------- –°—Ç–µ–π—Ç –∏ –º–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö ----------
@dataclass
class PhotoCheck:
    captured: bool = False
    passed: Optional[bool] = None
    angle_expected: Optional[str] = None
    angle_detected: Optional[str] = None
    clean: Optional[bool] = None
    damage: Optional[bool] = None
    notes: Optional[str] = None
    preview: Optional[bytes] = None  # –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è

def init_state():
    if "step" not in st.session_state:
        st.session_state.step = "welcome"  # welcome -> selfie_doc -> car_front -> car_side_left -> car_rear -> car_side_right -> summary

    if "selfie_doc" not in st.session_state:
        st.session_state.selfie_doc = None
    if "face_match" not in st.session_state:
        st.session_state.face_match = None

    if "checks" not in st.session_state:
        st.session_state.checks = {
            "front": PhotoCheck(angle_expected="front"),
            "side_left": PhotoCheck(angle_expected="side-left"),
            "rear": PhotoCheck(angle_expected="rear"),
            "side_right": PhotoCheck(angle_expected="side-right"),
        }

    # –°—á—ë—Ç—á–∏–∫–∏ –¥–ª—è —Å–±—Ä–æ—Å–∞ –∫–∞–º–µ—Ä—ã (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ key —É st.camera_input)
    if "camera_attempts" not in st.session_state:
        st.session_state.camera_attempts = {
            "selfie_doc": 0,
            "front": 0,
            "side_left": 0,
            "rear": 0,
            "side_right": 0,
        }

def go(next_step: str):
    st.session_state.step = next_step
    st.rerun()

def reset_camera(step_key: str):
    st.session_state.camera_attempts[step_key] += 1
    if step_key == "selfie_doc":
        st.session_state.selfie_doc = None
        st.session_state.face_match = None
    else:
        chk: PhotoCheck = st.session_state.checks[step_key]
        chk.captured = False
        chk.preview = None
        chk.angle_detected = None
        chk.clean = None
        chk.damage = None
        chk.notes = None
        chk.passed = None
    st.rerun()

# ---------- UI ----------
st.set_page_config(page_title="–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–µ–∑–¥–∫–∏", page_icon="üöó", layout="centered")
st.title("üöó –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–µ–∑–¥–∫–∏")
st.caption("Streamlit ‚Ä¢ DeepFace (1 —Ñ–æ—Ç–æ) ‚Ä¢ Qwen2.5-VL ‚Ä¢ Camera reset")

init_state()

with st.sidebar:
    st.header("–®–∞–≥–∏")
    steps = [
        ("welcome", "–°—Ç–∞—Ä—Ç"),
        ("selfie_doc", "–°–µ–ª—Ñ–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–º"),
        ("car_front", "–§–æ—Ç–æ –∞–≤—Ç–æ —Å–ø–µ—Ä–µ–¥–∏"),
        ("car_side_left", "–§–æ—Ç–æ –∞–≤—Ç–æ —Å–ª–µ–≤–∞"),
        ("car_rear", "–§–æ—Ç–æ –∞–≤—Ç–æ —Å–∑–∞–¥–∏"),
        ("car_side_right", "–§–æ—Ç–æ –∞–≤—Ç–æ —Å–ø—Ä–∞–≤–∞"),
        ("summary", "–ò—Ç–æ–≥"),
    ]
    for key, label in steps:
        flag = "‚úÖ" if (st.session_state.step == key or
                       (key == "summary" and st.session_state.step == "summary")) else ""
        st.write(f"{flag} {label}")

# -------- –•–ï–õ–ü–ï–† –î–õ–Ø –®–ê–ì–û–í –ê–í–¢–û --------
def car_step_ui(step_key: str, title: str, hint: str):
    st.subheader(title)
    st.write(hint)

    cam_key = f"cam_{step_key}_{st.session_state.camera_attempts[step_key]}"
    shot = st.camera_input("–°–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ", key=cam_key)

    chk: PhotoCheck = st.session_state.checks[step_key]
    if shot:
        img = file_to_pil(shot)
        st.image(img, caption="–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä", use_column_width=True)

        with st.spinner("–ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ (Qwen2.5-VL)‚Ä¶"):
            result = analyze_car_image(img)

        chk.captured = True
        chk.preview = shot.getvalue()
        chk.angle_detected = result.get("angle", "unknown")
        chk.clean = bool(result.get("clean", False))
        chk.damage = bool(result.get("damage", True))
        chk.notes = str(result.get("notes", ""))

        # –ü—Ä–æ—Ö–æ–¥–Ω–æ–π –∫—Ä–∏—Ç–µ—Ä–∏–π: –≤–µ—Ä–Ω—ã–π —Ä–∞–∫—É—Ä—Å + —á–∏—Å—Ç–æ + –±–µ–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        chk.passed = (chk.angle_detected == chk.angle_expected) and chk.clean and (not chk.damage)

        cols = st.columns(3)
        cols[0].metric("–û–∂–∏–¥–∞–µ–º—ã–π —Ä–∞–∫—É—Ä—Å", chk.angle_expected or "-")
        cols[1].metric("–û–ø—Ä–µ–¥–µ–ª—ë–Ω —Ä–∞–∫—É—Ä—Å", chk.angle_detected or "-")
        cols[2].metric("–°—Ç–∞—Ç—É—Å", "‚úÖ OK" if chk.passed else "‚ùå –ù–µ –ø—Ä–æ–π–¥–µ–Ω–æ")

        st.write(f"–ß–∏—Å—Ç–æ—Ç–∞: **{chk.clean}**, –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è: **{chk.damage}**")
        if chk.notes:
            st.caption(f"–ó–∞–º–µ—Ç–∫–∏: {chk.notes}")

        next_map = {
            "front": "car_side_left",
            "side_left": "car_rear",
            "rear": "car_side_right",
            "side_right": "summary",
        }

        btn_cols = st.columns(2)
        if btn_cols[0].button("–°–¥–µ–ª–∞—Ç—å –¥—Ä—É–≥–æ–µ —Ñ–æ—Ç–æ üîÑ"):
            reset_camera(step_key)
        if btn_cols[1].button("–î–∞–ª—å—à–µ ‚û°Ô∏è", type="primary"):
            go(next_map[step_key])
    else:
        st.button("–°–±—Ä–æ—Å–∏—Ç—å –∫–∞–º–µ—Ä—É üîÑ", on_click=reset_camera, args=(step_key,))

# -------- –†–û–£–¢–ò–ù–ì –®–ê–ì–û–í --------
if st.session_state.step == "welcome":
    st.subheader("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å!")
    st.write("–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –æ—Å–º–æ—Ç—Ä–∞ –∞–≤—Ç–æ.")
    if st.button("–ù–∞—á–∞—Ç—å –ø–æ–µ–∑–¥–∫—É ‚ñ∂Ô∏è", type="primary"):
        go("selfie_doc")

elif st.session_state.step == "selfie_doc":
    st.subheader("–°–µ–ª—Ñ–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–º (1 —Ñ–æ—Ç–æ)")
    st.write("–î–µ—Ä–∂–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç —Ç–∞–∫, —á—Ç–æ–±—ã –±—ã–ª–æ –≤–∏–¥–Ω–æ –≤–∞—à–µ –ª–∏—Ü–æ –∏ –ø–æ—Ä—Ç—Ä–µ—Ç –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–µ. –í –∫–∞–¥—Ä–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ç–æ–ª—å–∫–æ –≤—ã.")

    cam_key = f"cam_selfie_{st.session_state.camera_attempts['selfie_doc']}"
    shot = st.camera_input("–°–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ (—Å–µ–ª—Ñ–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–º)", key=cam_key)

    if shot:
        st.session_state.selfie_doc = file_to_pil(shot)
        st.image(st.session_state.selfie_doc, caption="–°–µ–ª—Ñ–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–º", use_column_width=True)

        with st.spinner("–ò—â–µ–º –¥–≤–∞ –ª–∏—Ü–∞ –∏ —Å–≤–µ—Ä—è–µ–º (DeepFace)‚Ä¶"):
            matched, distance, err, num_faces = verify_two_faces_in_one(st.session_state.selfie_doc)

        if err:
            st.error(err)
            st.button("–°–¥–µ–ª–∞—Ç—å –¥—Ä—É–≥–æ–µ —Ñ–æ—Ç–æ üîÑ", on_click=reset_camera, args=("selfie_doc",))
        else:
            st.session_state.face_match = {"matched": matched, "distance": distance, "num_faces": num_faces}
            if matched:
                st.success(f"–õ–∏—Ü–∞ —Å–æ–≤–ø–∞–¥–∞—é—Ç ‚úÖ (distance={distance:.4f})")
                if st.button("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∫ –∞–≤—Ç–æ ‚û°Ô∏è", type="primary"):
                    go("car_front")
            else:
                st.error(f"–î–≤–∞ –ª–∏—Ü–∞ –Ω–∞–π–¥–µ–Ω—ã, –Ω–æ –æ–Ω–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç ‚ùå (distance={distance:.4f}). "
                         "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ä–∞–∫—É—Ä—Å/–æ—Å–≤–µ—â–µ–Ω–∏–µ.")
                st.button("–°–¥–µ–ª–∞—Ç—å –¥—Ä—É–≥–æ–µ —Ñ–æ—Ç–æ üîÑ", on_click=reset_camera, args=("selfie_doc",))
    else:
        st.button("–°–±—Ä–æ—Å–∏—Ç—å –∫–∞–º–µ—Ä—É üîÑ", on_click=reset_camera, args=("selfie_doc",))

elif st.session_state.step == "car_front":
    car_step_ui(
        "front",
        "–§–æ—Ç–æ –∞–≤—Ç–æ —Å–ø–µ—Ä–µ–¥–∏",
        "–°—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–π—Ç–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—å —Å—Ç—Ä–æ–≥–æ —Å–ø–µ—Ä–µ–¥–∏. –ö–∞–º–µ—Ä—É –¥–µ—Ä–∂–∏—Ç–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ñ–∞—Ä."
    )

elif st.session_state.step == "car_side_left":
    car_step_ui(
        "side_left",
        "–§–æ—Ç–æ –∞–≤—Ç–æ —Å–ª–µ–≤–∞ (–±–æ–∫)",
        "–°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ –ª–µ–≤–æ–≥–æ –±–æ—Ä—Ç–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è –ø–æ–ª–Ω–æ—Å—Ç—å—é, –∫–æ–ª—ë—Å–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤–∏–¥–Ω—ã."
    )

elif st.session_state.step == "car_rear":
    car_step_ui(
        "rear",
        "–§–æ—Ç–æ –∞–≤—Ç–æ —Å–∑–∞–¥–∏",
        "–°–Ω–∏–º–∏—Ç–µ –∞–≤—Ç–æ —Å—Ç—Ä–æ–≥–æ —Å–∑–∞–¥–∏. –ù–æ–º–µ—Ä –∏ —Ñ–æ–Ω–∞—Ä–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –∫–∞–¥—Ä–µ."
    )

elif st.session_state.step == "car_side_right":
    car_step_ui(
        "side_right",
        "–§–æ—Ç–æ –∞–≤—Ç–æ —Å–ø—Ä–∞–≤–∞ (–±–æ–∫)",
        "–°—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–π—Ç–µ –ø—Ä–∞–≤—ã–π –±–æ—Ä—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª—è –ø–æ–ª–Ω–æ—Å—Ç—å—é."
    )

elif st.session_state.step == "summary":
    st.subheader("–ò—Ç–æ–≥–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏")

    # –ò—Ç–æ–≥ –ø–æ –ª–∏—Ü–∞–º
    face_ok = bool(st.session_state.face_match and st.session_state.face_match.get("matched"))
    col_a, col_b = st.columns(2)
    with col_a:
        st.markdown("**–°–≤–µ—Ä–∫–∞ –ª–∏—Ü–∞ (DeepFace):** " + ("‚úÖ –£—Å–ø–µ—Ö" if face_ok else "‚ùå –ù–µ –ø—Ä–æ–π–¥–µ–Ω–æ"))
        fm = st.session_state.face_match or {}
        if fm.get("distance") is not None:
            st.caption(f"distance = {fm['distance']:.4f}")
        if fm.get("num_faces") is not None:
            st.caption(f"–æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: {fm['num_faces']}")
    with col_b:
        st.markdown("**–§–æ—Ç–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è:**")

    # –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –ø–æ 4 —Ä–∞–∫—É—Ä—Å–∞–º
    problems = []
    for k, label in [
        ("front", "–°–ø–µ—Ä–µ–¥–∏"),
        ("side_left", "–°–ª–µ–≤–∞"),
        ("rear", "–°–∑–∞–¥–∏"),
        ("side_right", "–°–ø—Ä–∞–≤–∞"),
    ]:
        chk: PhotoCheck = st.session_state.checks[k]
        status = "‚úÖ OK" if chk.passed else "‚ùå"
        st.write(f"- **{label}:** {status} "
                 f"(–æ–∂–∏–¥–∞–ª–∏: `{chk.angle_expected}`, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ: `{chk.angle_detected}`, "
                 f"clean={chk.clean}, damage={chk.damage})")
        if not chk.passed:
            if chk.angle_detected != chk.angle_expected:
                problems.append(f"{label}: –Ω–µ–≤–µ—Ä–Ω—ã–π —Ä–∞–∫—É—Ä—Å (–æ–∂–∏–¥–∞–ª–∏ {chk.angle_expected}, –ø–æ–ª—É—á–∏–ª–∏ {chk.angle_detected})")
            if chk.clean is False:
                problems.append(f"{label}: –∞–≤—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –≥—Ä—è–∑–Ω—ã–º")
            if chk.damage is True:
                problems.append(f"{label}: –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è")
            if chk.notes:
                problems.append(f"{label}: –∑–∞–º–µ—Ç–∫–∏ ‚Äî {chk.notes}")

    all_ok = face_ok and all(v.passed for v in st.session_state.checks.values())

    st.markdown("---")
    if all_ok:
        st.success("üéâ SUCCESS ‚Äî –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã!")
    else:
        st.error("–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã.")
        if problems:
            st.markdown("**–ß—Ç–æ –Ω–µ —Ç–∞–∫:**")
            for p in problems:
                st.write(f"‚Ä¢ {p}")

    # –ö–Ω–æ–ø–∫–∏
    col1, col2 = st.columns(2)
    if col1.button("–ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ üîÑ"):
        for key in ["step", "selfie_doc", "face_match", "checks", "camera_attempts"]:
            if key in st.session_state:
                del st.session_state[key]
        st.rerun()
    if col2.button("–ó–∞–≤–µ—Ä—à–∏—Ç—å ‚úÖ"):
        st.success("–ì–æ—Ç–æ–≤–æ! –ú–æ–∂–µ—Ç–µ –∑–∞–∫—Ä—ã—Ç—å –æ–∫–Ω–æ.")
